version: "1.0.0"

lakebridge:
    description: >
        Unified configuration for type normalization rules.
        Each category defines transformations that standardize data types
        across dialects before comparison.

    categories:
        # ------------------------------------------------------------------------
        # TEMPORAL CATEGORY
        # ------------------------------------------------------------------------
        temporal:
            description: >
                Temporal types across dialects.

            # Per-category dialect type mapping -> canonical classes
            type_map:
                canonical_classes: ["DATE", "TIME", "TIMESTAMP", "TIMESTAMP_TZ", "INTERVAL"]
                tsql:
                    DATE: ["DATE"]
                    TIME: ["TIME"]
                    TIMESTAMP: ["DATETIME2", "DATETIME", "SMALLDATETIME"]
                    TIMESTAMP_TZ: ["DATETIMEOFFSET"]
                    INTERVAL: []
                oracle:
                    DATE: ["DATE"] # Oracle DATE includes time component. treat as DATE here for normalization.
                    TIME: []
                    TIMESTAMP: ["TIMESTAMP"]
                    TIMESTAMP_TZ: ["TIMESTAMP WITH TIME ZONE", "TIMESTAMP WITH LOCAL TIME ZONE"]
                    INTERVAL: ["INTERVAL YEAR TO MONTH", "INTERVAL DAY TO SECOND"]
                snowflake:
                    DATE: ["DATE"]
                    TIME: ["TIME"]
                    TIMESTAMP: ["DATETIME", "TIMESTAMP_NTZ"]
                    TIMESTAMP_TZ: ["TIMESTAMP_TZ", "TIMESTAMP_LTZ"]
                    INTERVAL: []
                databricks:
                    DATE: ["DATE"]
                    TIME: []
                    TIMESTAMP: ["TIMESTAMP_NTZ"]
                    TIMESTAMP_TZ: ["TIMESTAMP"]
                    INTERVAL: ["INTERVAL"]

            transformations:

                date_to_iso8601:
                    description: "Normalize DATE to ISO 8601 (YYYY-MM-DD)."
                    applies_to: ["DATE"]
                    dialects:
                        tsql:
                            sql: "CONVERT(VARCHAR(10), {}, 23)"
                        snowflake:
                            sql: "TO_VARCHAR({}, 'YYYY-MM-DD')"
                        databricks:
                            sql: "DATE_FORMAT({}, 'yyyy-MM-dd')"
                        oracle:
                            sql: "TO_CHAR({}, 'YYYY-MM-DD')"
                    test_cases:
                        - name: "standard_date"
                          input: "2025-10-24"
                          expected_output: "2025-10-24"
                        - name: "null_handling"
                          input: null
                          expected_output: null

                timestamp_to_iso8601:
                    description: "Normalize TIMESTAMP (no tz) to ISO 8601 with microseconds."
                    applies_to: ["TIMESTAMP"]
                    dialects:
                        snowflake:
                            sql: "TO_VARCHAR({}, 'YYYY-MM-DD HH24:MI:SS.FF6')"
                        oracle:
                            sql: "TO_CHAR({}, 'YYYY-MM-DD HH24:MI:SS.FF6')"
                        tsql:
                            sql: "CONVERT(VARCHAR(27), {}, 126)"
                        databricks:
                            sql: "DATE_FORMAT({}, 'yyyy-MM-dd HH:mm:ss.SSSSSS')"
                    test_cases:
                        - name: "standard_timestamp"
                          input: "2025-10-24 13:45:30.123456"
                          expected_output: "2025-10-24 13:45:30.123456"

                timestamptz_to_iso8601:
                    description: "Normalize TIMESTAMP with time zone to ISO 8601 with microseconds."
                    applies_to: ["TIMESTAMP_TZ"]
                    dialects:
                        snowflake:
                            sql: "TO_VARCHAR({}, 'YYYY-MM-DD HH24:MI:SS.FF6 TZH:TZM')"
                        oracle:
                            sql: "TO_CHAR({}, 'YYYY-MM-DD HH24:MI:SS.FF6 TZH:TZM')"
                        tsql:
                            sql: "REPLACE(CONVERT(VARCHAR(33), CAST({} AS DATETIME2(6)), 126), 'T', ' ')"
                        databricks:
                            sql: "DATE_FORMAT({}, 'yyyy-MM-dd HH:mm:ss.SSSSSS ZZZZZ')"
                    test_cases:
                        - name: "with_offset"
                          input: "2025-10-24 13:45:30.123456 +02:00"
                          expected_output: "2025-10-24 13:45:30.123456 +02:00"

                time_to_hhmmss:
                    description: "Normalize TIME to HH:MM:SS[.ffffff]."
                    applies_to: ["TIME"]
                    dialects:
                        snowflake:
                            sql: "TO_VARCHAR({}, 'HH24:MI:SS.FF6')"
                        tsql:
                            sql: "FORMAT({}, 'HH:mm:ss.ffffff')"
                    test_cases:
                        - name: "standard_time"
                          input: "13:45:30"
                          expected_output: "13:45:30"

        numeric:
            description: >
                Numeric types represent numbers, including integers, decimals, and floatingâ€‘point values.

            # Per-category dialect type mapping -> canonical numeric classes
            type_map:
                canonical_classes: ["INTEGER", "DECIMAL", "FLOAT"]
                tsql: # implement
                    INTEGER: []
                    DECIMAL: []
                    FLOAT: []
                oracle:
                    INTEGER: []
                    DECIMAL: ["NUMBER"]
                    FLOAT: ["BINARY_DOUBLE", "BINARY_FLOAT"]
                snowflake: # implement
                    INTEGER: []
                    DECIMAL: []
                    FLOAT: []
                databricks:
                    INTEGER: ["TINYINT", "SMALLINT", "INT", "BIGINT"]
                    DECIMAL: ["DECIMAL"]
                    FLOAT: ["FLOAT", "DOUBLE"]
